{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from random import choice, randint\n",
    "\n",
    "from torchvision import models, utils\n",
    "from torchvision.datasets import ImageFolder, FakeData\n",
    "from torchvision.transforms.v2 import Compose, Resize, ToImage, ToDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = 3\n",
    "width = 224\n",
    "height = 224\n",
    "fake_images = FakeData(1000, (channel, width, height))\n",
    "\n",
    "class RandomBackground(torch.nn.Module):\n",
    "    def forward(self, img):\n",
    "        # Pick a random background image from the fake dataset\n",
    "        background = choice(fake_images)[0]\n",
    "\n",
    "        # Pick a random location, but makesure at least he top left quarter of the image will be visible\n",
    "        x, y = randint(0, background.width-img.width//2), randint(0, background.height-img.height//2)\n",
    "\n",
    "        # Put the image of the card on top of the background with the top left corner at the randomly selected loaction\n",
    "        background.paste(img, (x, y))\n",
    "        return background\n",
    "\n",
    "\n",
    "add_background = Compose([\n",
    "    # resize the images to be half the height of the background image\n",
    "    Resize((height * 3 // 4, width // 2)),\n",
    "\n",
    "    # And a random background to the image\n",
    "    RandomBackground(),\n",
    "\n",
    "    # Convert the image to a tensor scaled between 0 and 1\n",
    "    ToImage(),\n",
    "    ToDtype(torch.float32, scale=True),\n",
    "])\n",
    "\n",
    "cards_with_background = ImageFolder('../data/bicycle_cards', transform=add_background)\n",
    "train_loader = torch.utils.data.DataLoader(cards_with_background, batch_size=8, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(cards_with_background, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "import torch.optim as optim\n",
    "\n",
    "class lightningClassifier(L.LightningModule):\n",
    "    def __init__(self, model) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.model(x)\n",
    "        loss = nn.functional.cross_entropy(z, y)\n",
    "        # self.log(\"my_loss\", loss, prog_bar=True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        z = self.model(x)\n",
    "        acc = (y == z.argmax(-1)).sum() / 52\n",
    "        self.log(\"acc\", acc, prog_bar=True)\n",
    "        return acc\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "\n",
    "model_ft = models.resnet18(weights='IMAGENET1K_V1')\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, len(cards_with_background.classes))\n",
    "\n",
    "classifier = lightningClassifier(model_ft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = L.Trainer(max_epochs=100)\n",
    "trainer.fit(model=classifier, train_dataloaders=train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_loader = torch.utils.data.DataLoader(cards_with_background, batch_size=24, shuffle=True)\n",
    "\n",
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "def visualize_model(model, num_images=6):\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig = plt.figure()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(val_loader):\n",
    "            # inputs = inputs.to(device)\n",
    "            # labels = labels.to(device)\n",
    "            print(inputs.shape)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                images_so_far += 1\n",
    "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
    "                ax.axis('off')\n",
    "                ax.set_title(f'predicted: {cards_with_background.classes[preds[j].item()]}')\n",
    "                imshow(inputs.cpu().data[j])\n",
    "\n",
    "                if images_so_far == num_images:\n",
    "                    model.train(mode=was_training)\n",
    "                    return\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "inputs, classes = next(iter(val_loader))\n",
    "# Make a grid from batch\n",
    "out = utils.make_grid(inputs)\n",
    "visualize_model(model_ft, 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
